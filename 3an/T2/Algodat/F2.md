- En korrupterad single linked list kan sluta loopa om man använder haren och sköldpaddan:
![[Pasted image 20240321102157.png]]
* Man kan optimera append genom att head node pekar på första och sista:
![[Pasted image 20240321102257.png]]
*Insert är mycket långsammare än append i single linked(?).
- Double linked list:
![[Pasted image 20240321102332.png]]
*Dubbellänkat gör det lätt att ta bort inuti*
- Circular double linked list:
![[Pasted image 20240321102348.png]]
*Beware of infinite loops!*

**Binärt sökträd**
* Tree node t
* left(t) = null or key(left(t)) < key(t)
* right(t) = null or key(right(t)) > key(t)
* Utan balansering är insert, search och delte O(n). Med balansering genom *AVL* eller *red-black* blir det O(log n)
- AVL balance attribute:
![[Pasted image 20240321102804.png]]
* Single rotations:
![[Pasted image 20240321102836.png]]
- Double rotations:
![[Pasted image 20240321102856.png]]

**Hash maps or hash tables**
* Store (key, value) pairs using an array of size m.
* Compute an index from the key (modulo m) using a hash function.
* When two keys are mapped to the same index there is a collision. Two main ways to handle:
	* separate chaining (öppen hashtabell)
	* open addressing (sluten hashtabell)
- With n pairs, $\alpha = \frac{n}{m}$ is the load factor
- Separate chaining uses linked lists for the pairs
- Open addressing stores the pairs in the array

**Separate chaining**
- Table is an array of linked lists
- Compared with only one list, this will likely be m times faster
- Some alternatives for fast insertion:
	- Always insert at the beginning (no search needed if you know it is a new pair)
	- Keep each list sorted
	- Move frequently used pairs to the beginning of the list
- Advantage: simple to implement
- Disadvantage: less simple to allocate memory for the list nodes efficiently (constantly allocating and garbage collecting nodes takes time)
- Usually a good choice
- If $\alpha$ gets too big, the operations will be slower but still work.
- Resize array if needed

**Open addressing**
- Jämfört med separate chaining kan vi inte alls ha $\alpha > 1$.
- Three ways to handle collisions:
	- Linear probing
	- Quadratic probing
	- Double hashing probing

**Linear probing**
- If $a[f(key)]$ is not empty try $a[f(key) + 1]$ and so on until an empty node is found. Similar for search
- Sometimes it is simpler to have an array each for keys and values with the pair sharing the same index i in the two arrays.
- The issue is that once we delete elements we might not find some keys as the conditions are not the same for placement.
	- This can be solved by placing a value "deleted" to solve this. However, this may store many "deleted" that must be skipped.
		- If we have too many "deleted" we can clean the hash table to remove them by reinserting everything
	- Another solution is to move everything left when you delete, however, then we might move something out of its original position.
		- Correct delete using this solution:![[Pasted image 20240321104740.png]] 

- A simple model of unsuccessful search in linear probing:
	- We ignore clustering and instead assume all positions are equally likely to be occupied.
	- If the random variable X is the number of probes in an unsuccessful search, what is the expected value $E[X]$?
	- $P(X \geq k)$ is the probability that the first k-1 positions are occupied, and the last is empty.
	- $P(X \geq k) = \frac{n}{m} \frac{{n-1}}{m-1} \dots \frac{{n-k + 2}}{m-k + 2} \leq (\frac{n}{m})^{k-1}=\alpha^{k-1}$
	- $$E(X)=\sum^{\infty}_{k=1}kP(X=k) = \dots = \sum^{\infty}_{k=1}P(X\geq k) \leq \sum^{\infty}_{k=1}\alpha^{k-1}=\sum^{\infty}_{k=0}=\frac{1}{1-\alpha}$$![[Pasted image 20240321105704.png]]
		- This is even optimistic as clustering is ignored.
**Quadratic probing**
- Reduces risk of clustering by adding $i^{2}$ instead of $i$ to the initial hash value. As such we should leave a cluster quickly.
- Clustering is reduced but if two different keys have the same hash value, there can be secondary clustering since the positions probed will be the same.
- The problem is that we cannot for a given m guarantee that we will find an empty position if there is one.
- Lemma if $m$ is prime and $\alpha = \frac{n}{m} < \frac{1}{2}$ and $i \neq j$, then quadratic probing will find an empty position in less than $\frac{m}{2}$ probes.
	- Proof: Slide 30

 **Double hashing**
- We use an additional hash function:
  $h(k,i)=(h_{1}(k)+ih_{2}(k))$ mod $m$
- Assume two different keys had the same hash value in quadratic probing, i.e. with $h_{1}(k)$. Then it is hoped that the risk that they have the same value also for $h_{2}(k)$ is much less.
- In practice this removes most clustering.
- By guaranteeing that $h_{2}(k)$ is relatively prime to $m$, all positions will be probed. Two simple ways to achieve this are:
	- let $m=2^{n}$ and ensure that $h_{2}(k)$ always is odd
	- let $m$ be prime and $0<h_{2}(k)<m$

**Summary of hash tables**
- No obvious "best" choice
- Best is to make performance measurements before changing anything, obviously.
- Especially the number of cache misses can explain performance differences.

**Graphs**
- Notation:
  ![[Pasted image 20240321135459.png|500]]
- *Undirected graph* describes friends on a social network
- *Directed graphs* are e.g. one-way flight connections
- Graph representation: adjacency matrix
	- Often two representations of each edge. If there is an edge (i, j) then one is stored both in $m[i][j]$ and in $m[j][i]$, otherwise a zero.
	- If n is large it can be a good idea to store only half the matrix.
- Graph representation: adjacency list
	- Every vertex has a list of neighbors
	- Every edge u - v is stored in both u and v
	- degree(n) is the number of neighbors
	- $\Theta(\text{degree}(n))$ time to fund all neighbors of a node
	- $\Theta(m)$ time to list all edges
- Optimization:
	- Store only half of the adjacency matrix for undirected graphs
	- For a very dense graph the matrix is smaller and just as fast
	- If you need both quick neighbor check and being able to quickly list all neighbors, then use both!
- Paths and connectivity:
	- A *path* is a sequence of nodes $p=(v_{1},v_{2},\dots, v_{k})$ such that $v_{i}$ and $v_{i+1}$ are neighbors in an undirected graph, or there is an edge from first to the second in a directed graph.
	- If all nodes in $p$ are distinct then it is a *simple path*
	- An undirected graph is *connected* if there is a path between every pair of nodes.
	- A *cycle* is a path which consists of a simple path followed by the first node such as (u, v, w, u)
	- A connected undirected graph is a *tree* if it has no cycle.
		- A tree has $n-1$ edges.
		- In a *rooted tree* one node, r is called the node.

**DFS**
![[Pasted image 20240321141254.png|500]]
- Example:
  ![[Pasted image 20240321141344.png|450]]
**The s-t connectivity problem**
- The problem is to find a path from s to t. Often we want to find the shortest path from s to t.
- The *distance* between two nodes u and v is the number of edges on a shortest path from u to v.
- *BFS* (breadth first search):
	- Check all nodes v at a distance k from s until either v = t or there are no more nodes to check, in which case s and t are not connected.
	- Implementation:
		![[Pasted image 20240321141618.png|450]]
- 

**Allmänt**
- Skeppstedt gillar korta var.namn lol
- Om $m < n$ $\Leftrightarrow$ $\alpha > 1$ innebär för seprate chaining att vi bara får längre länkade listor men får open addressing går det ej då vi inte kan ha färre platser än värden.
- En bra hashfunktion fördelar upptagna platser uniformt. Problemet med linear hashing är att vi steger linjärt fram vilket skapar kluster med upptagna platser. Detta löser quadratic probing och double hashing då de försöker lämna klustret snabbt.